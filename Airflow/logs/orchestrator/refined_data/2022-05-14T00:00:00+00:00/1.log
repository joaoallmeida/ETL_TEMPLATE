[2022-05-15 19:43:14,894] {taskinstance.py:1035} INFO - Dependencies all met for <TaskInstance: orchestrator.refined_data manual__2022-05-15T19:42:55.820330+00:00 [queued]>
[2022-05-15 19:43:15,099] {taskinstance.py:1035} INFO - Dependencies all met for <TaskInstance: orchestrator.refined_data manual__2022-05-15T19:42:55.820330+00:00 [queued]>
[2022-05-15 19:43:15,099] {taskinstance.py:1241} INFO - 
--------------------------------------------------------------------------------
[2022-05-15 19:43:15,099] {taskinstance.py:1242} INFO - Starting attempt 1 of 2
[2022-05-15 19:43:15,099] {taskinstance.py:1243} INFO - 
--------------------------------------------------------------------------------
[2022-05-15 19:43:15,129] {taskinstance.py:1035} INFO - Dependencies all met for <TaskInstance: orchestrator.refined_data scheduled__2022-05-14T00:00:00+00:00 [queued]>
[2022-05-15 19:43:15,237] {taskinstance.py:1035} INFO - Dependencies all met for <TaskInstance: orchestrator.refined_data scheduled__2022-05-14T00:00:00+00:00 [queued]>
[2022-05-15 19:43:15,237] {taskinstance.py:1241} INFO - 
--------------------------------------------------------------------------------
[2022-05-15 19:43:15,238] {taskinstance.py:1242} INFO - Starting attempt 1 of 2
[2022-05-15 19:43:15,238] {taskinstance.py:1262} INFO - Executing <Task(PythonOperator): refined_data> on 2022-05-15 19:42:55.820330+00:00
[2022-05-15 19:43:15,238] {taskinstance.py:1243} INFO - 
--------------------------------------------------------------------------------
[2022-05-15 19:43:15,245] {standard_task_runner.py:52} INFO - Started process 1222 to run task
[2022-05-15 19:43:15,249] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'orchestrator', 'refined_data', 'manual__2022-05-15T19:42:55.820330+00:00', '--job-id', '53', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmptgtyt9qk', '--error-file', '/tmp/tmp_9iprrr0']
[2022-05-15 19:43:15,250] {standard_task_runner.py:77} INFO - Job 53: Subtask refined_data
[2022-05-15 19:43:15,304] {taskinstance.py:1262} INFO - Executing <Task(PythonOperator): refined_data> on 2022-05-14 00:00:00+00:00
[2022-05-15 19:43:15,308] {standard_task_runner.py:52} INFO - Started process 1223 to run task
[2022-05-15 19:43:15,312] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'orchestrator', 'refined_data', 'scheduled__2022-05-14T00:00:00+00:00', '--job-id', '54', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmpngggnbh3', '--error-file', '/tmp/tmpjbbeqz9h']
[2022-05-15 19:43:15,313] {standard_task_runner.py:77} INFO - Job 54: Subtask refined_data
[2022-05-15 19:43:15,337] {logging_mixin.py:109} INFO - Running <TaskInstance: orchestrator.refined_data manual__2022-05-15T19:42:55.820330+00:00 [running]> on host 87efc59194bd
[2022-05-15 19:43:15,388] {logging_mixin.py:109} INFO - Running <TaskInstance: orchestrator.refined_data scheduled__2022-05-14T00:00:00+00:00 [running]> on host 87efc59194bd
[2022-05-15 19:43:15,514] {taskinstance.py:1414} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=***@example.com
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=orchestrator
AIRFLOW_CTX_TASK_ID=refined_data
AIRFLOW_CTX_EXECUTION_DATE=2022-05-15T19:42:55.820330+00:00
AIRFLOW_CTX_DAG_RUN_ID=manual__2022-05-15T19:42:55.820330+00:00
[2022-05-15 19:43:15,515] {refined.py:19} INFO - Starting the data refinement process
[2022-05-15 19:43:15,535] {base.py:79} INFO - Using connection to: id: MySql Localhost. Host: 192.168.15.14, Port: 3306, Schema: , Login: db_user, Password: ***, extra: {}
[2022-05-15 19:43:15,608] {taskinstance.py:1414} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=***@example.com
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=orchestrator
AIRFLOW_CTX_TASK_ID=refined_data
AIRFLOW_CTX_EXECUTION_DATE=2022-05-14T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-05-14T00:00:00+00:00
[2022-05-15 19:43:15,609] {refined.py:19} INFO - Starting the data refinement process
[2022-05-15 19:43:15,626] {base.py:79} INFO - Using connection to: id: MySql Localhost. Host: 192.168.15.14, Port: 3306, Schema: , Login: db_user, Password: ***, extra: {}
[2022-05-15 19:43:15,825] {base.py:79} INFO - Using connection to: id: MySql Localhost. Host: 192.168.15.14, Port: 3306, Schema: , Login: db_user, Password: ***, extra: {}
[2022-05-15 19:43:15,892] {base.py:79} INFO - Using connection to: id: MySql Localhost. Host: 192.168.15.14, Port: 3306, Schema: , Login: db_user, Password: ***, extra: {}
[2022-05-15 19:43:16,890] {refined.py:84} INFO - Not found changes
[2022-05-15 19:43:16,909] {base.py:79} INFO - Using connection to: id: MySql Localhost. Host: 192.168.15.14, Port: 3306, Schema: , Login: db_user, Password: ***, extra: {}
[2022-05-15 19:43:16,923] {refined.py:84} INFO - Not found changes
[2022-05-15 19:43:16,944] {base.py:79} INFO - Using connection to: id: MySql Localhost. Host: 192.168.15.14, Port: 3306, Schema: , Login: db_user, Password: ***, extra: {}
[2022-05-15 19:43:17,197] {refined.py:93} INFO - Ending the data refinement process
[2022-05-15 19:43:17,198] {refined.py:93} INFO - Ending the data refinement process
[2022-05-15 19:43:17,199] {python.py:152} INFO - Done. Returned value was: None
[2022-05-15 19:43:17,199] {python.py:152} INFO - Done. Returned value was: None
[2022-05-15 19:43:17,220] {taskinstance.py:1280} INFO - Marking task as SUCCESS. dag_id=orchestrator, task_id=refined_data, execution_date=20220515T194255, start_date=20220515T194314, end_date=20220515T194317
[2022-05-15 19:43:17,220] {taskinstance.py:1280} INFO - Marking task as SUCCESS. dag_id=orchestrator, task_id=refined_data, execution_date=20220514T000000, start_date=20220515T194315, end_date=20220515T194317
[2022-05-15 19:43:17,306] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-05-15 19:43:17,328] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-05-15 19:43:17,389] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-05-15 19:43:17,400] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-05-15 19:47:37,580] {taskinstance.py:1035} INFO - Dependencies all met for <TaskInstance: orchestrator.refined_data manual__2022-05-15T19:47:12.935448+00:00 [queued]>
[2022-05-15 19:47:37,677] {taskinstance.py:1035} INFO - Dependencies all met for <TaskInstance: orchestrator.refined_data manual__2022-05-15T19:47:12.935448+00:00 [queued]>
[2022-05-15 19:47:37,678] {taskinstance.py:1241} INFO - 
--------------------------------------------------------------------------------
[2022-05-15 19:47:37,678] {taskinstance.py:1242} INFO - Starting attempt 1 of 2
[2022-05-15 19:47:37,678] {taskinstance.py:1243} INFO - 
--------------------------------------------------------------------------------
[2022-05-15 19:47:37,744] {taskinstance.py:1262} INFO - Executing <Task(PythonOperator): refined_data> on 2022-05-15 19:47:12.935448+00:00
[2022-05-15 19:47:37,750] {standard_task_runner.py:52} INFO - Started process 1414 to run task
[2022-05-15 19:47:37,755] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'orchestrator', 'refined_data', 'manual__2022-05-15T19:47:12.935448+00:00', '--job-id', '61', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmpdzl9j1et', '--error-file', '/tmp/tmpcn0x_rcg']
[2022-05-15 19:47:37,756] {standard_task_runner.py:77} INFO - Job 61: Subtask refined_data
[2022-05-15 19:47:37,842] {logging_mixin.py:109} INFO - Running <TaskInstance: orchestrator.refined_data manual__2022-05-15T19:47:12.935448+00:00 [running]> on host 87efc59194bd
[2022-05-15 19:47:37,992] {taskinstance.py:1414} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=***@example.com
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=orchestrator
AIRFLOW_CTX_TASK_ID=refined_data
AIRFLOW_CTX_EXECUTION_DATE=2022-05-15T19:47:12.935448+00:00
AIRFLOW_CTX_DAG_RUN_ID=manual__2022-05-15T19:47:12.935448+00:00
[2022-05-15 19:47:37,993] {refined.py:19} INFO - Starting the data refinement process
[2022-05-15 19:47:38,011] {base.py:79} INFO - Using connection to: id: MySql Localhost. Host: 192.168.15.14, Port: 3306, Schema: , Login: db_user, Password: ***, extra: {}
[2022-05-15 19:47:38,157] {base.py:79} INFO - Using connection to: id: MySql Localhost. Host: 192.168.15.14, Port: 3306, Schema: , Login: db_user, Password: ***, extra: {}
[2022-05-15 19:47:39,164] {refined.py:72} INFO - Starting incremental load
[2022-05-15 19:47:39,273] {refined.py:76} INFO - Complete incremental load
[2022-05-15 19:47:39,301] {base.py:79} INFO - Using connection to: id: MySql Localhost. Host: 192.168.15.14, Port: 3306, Schema: , Login: db_user, Password: ***, extra: {}
[2022-05-15 19:47:39,451] {refined.py:81} INFO - Refined lines 26
[2022-05-15 19:47:39,451] {refined.py:93} INFO - Ending the data refinement process
[2022-05-15 19:47:39,453] {python.py:152} INFO - Done. Returned value was: None
[2022-05-15 19:47:39,483] {taskinstance.py:1280} INFO - Marking task as SUCCESS. dag_id=orchestrator, task_id=refined_data, execution_date=20220515T194712, start_date=20220515T194737, end_date=20220515T194739
[2022-05-15 19:47:39,570] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-05-15 19:47:39,642] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-05-15 19:47:40,144] {taskinstance.py:1035} INFO - Dependencies all met for <TaskInstance: orchestrator.refined_data scheduled__2022-05-14T00:00:00+00:00 [queued]>
[2022-05-15 19:47:40,186] {taskinstance.py:1035} INFO - Dependencies all met for <TaskInstance: orchestrator.refined_data scheduled__2022-05-14T00:00:00+00:00 [queued]>
[2022-05-15 19:47:40,186] {taskinstance.py:1241} INFO - 
--------------------------------------------------------------------------------
[2022-05-15 19:47:40,186] {taskinstance.py:1242} INFO - Starting attempt 1 of 2
[2022-05-15 19:47:40,186] {taskinstance.py:1243} INFO - 
--------------------------------------------------------------------------------
[2022-05-15 19:47:40,230] {taskinstance.py:1262} INFO - Executing <Task(PythonOperator): refined_data> on 2022-05-14 00:00:00+00:00
[2022-05-15 19:47:40,237] {standard_task_runner.py:52} INFO - Started process 1424 to run task
[2022-05-15 19:47:40,240] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'orchestrator', 'refined_data', 'scheduled__2022-05-14T00:00:00+00:00', '--job-id', '62', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmpv9ehud_w', '--error-file', '/tmp/tmp3ta_qpcc']
[2022-05-15 19:47:40,241] {standard_task_runner.py:77} INFO - Job 62: Subtask refined_data
[2022-05-15 19:47:40,332] {logging_mixin.py:109} INFO - Running <TaskInstance: orchestrator.refined_data scheduled__2022-05-14T00:00:00+00:00 [running]> on host 87efc59194bd
[2022-05-15 19:47:40,453] {taskinstance.py:1414} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=***@example.com
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=orchestrator
AIRFLOW_CTX_TASK_ID=refined_data
AIRFLOW_CTX_EXECUTION_DATE=2022-05-14T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-05-14T00:00:00+00:00
[2022-05-15 19:47:40,454] {refined.py:19} INFO - Starting the data refinement process
[2022-05-15 19:47:40,475] {base.py:79} INFO - Using connection to: id: MySql Localhost. Host: 192.168.15.14, Port: 3306, Schema: , Login: db_user, Password: ***, extra: {}
[2022-05-15 19:47:40,733] {base.py:79} INFO - Using connection to: id: MySql Localhost. Host: 192.168.15.14, Port: 3306, Schema: , Login: db_user, Password: ***, extra: {}
[2022-05-15 19:47:41,677] {refined.py:84} INFO - Not found changes
[2022-05-15 19:47:41,693] {base.py:79} INFO - Using connection to: id: MySql Localhost. Host: 192.168.15.14, Port: 3306, Schema: , Login: db_user, Password: ***, extra: {}
[2022-05-15 19:47:41,907] {refined.py:93} INFO - Ending the data refinement process
[2022-05-15 19:47:41,909] {python.py:152} INFO - Done. Returned value was: None
[2022-05-15 19:47:41,944] {taskinstance.py:1280} INFO - Marking task as SUCCESS. dag_id=orchestrator, task_id=refined_data, execution_date=20220514T000000, start_date=20220515T194740, end_date=20220515T194741
[2022-05-15 19:47:42,057] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-05-15 19:47:42,183] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-05-15 19:49:51,274] {taskinstance.py:1035} INFO - Dependencies all met for <TaskInstance: orchestrator.refined_data scheduled__2022-05-14T00:00:00+00:00 [queued]>
[2022-05-15 19:49:51,336] {taskinstance.py:1035} INFO - Dependencies all met for <TaskInstance: orchestrator.refined_data scheduled__2022-05-14T00:00:00+00:00 [queued]>
[2022-05-15 19:49:51,336] {taskinstance.py:1241} INFO - 
--------------------------------------------------------------------------------
[2022-05-15 19:49:51,337] {taskinstance.py:1242} INFO - Starting attempt 1 of 2
[2022-05-15 19:49:51,337] {taskinstance.py:1243} INFO - 
--------------------------------------------------------------------------------
[2022-05-15 19:49:51,402] {taskinstance.py:1262} INFO - Executing <Task(PythonOperator): refined_data> on 2022-05-14 00:00:00+00:00
[2022-05-15 19:49:51,407] {standard_task_runner.py:52} INFO - Started process 1518 to run task
[2022-05-15 19:49:51,410] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'orchestrator', 'refined_data', 'scheduled__2022-05-14T00:00:00+00:00', '--job-id', '67', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmpr6b65yjc', '--error-file', '/tmp/tmp6msh6uh3']
[2022-05-15 19:49:51,411] {standard_task_runner.py:77} INFO - Job 67: Subtask refined_data
[2022-05-15 19:49:51,513] {logging_mixin.py:109} INFO - Running <TaskInstance: orchestrator.refined_data scheduled__2022-05-14T00:00:00+00:00 [running]> on host 87efc59194bd
[2022-05-15 19:49:51,662] {taskinstance.py:1414} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=***@example.com
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=orchestrator
AIRFLOW_CTX_TASK_ID=refined_data
AIRFLOW_CTX_EXECUTION_DATE=2022-05-14T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-05-14T00:00:00+00:00
[2022-05-15 19:49:51,663] {refined.py:19} INFO - Starting the data refinement process
[2022-05-15 19:49:51,682] {base.py:79} INFO - Using connection to: id: MySql Localhost. Host: 192.168.15.14, Port: 3306, Schema: , Login: db_user, Password: ***, extra: {}
[2022-05-15 19:49:51,887] {base.py:79} INFO - Using connection to: id: MySql Localhost. Host: 192.168.15.14, Port: 3306, Schema: , Login: db_user, Password: ***, extra: {}
[2022-05-15 19:49:52,892] {refined.py:84} INFO - Not found changes
[2022-05-15 19:49:52,910] {base.py:79} INFO - Using connection to: id: MySql Localhost. Host: 192.168.15.14, Port: 3306, Schema: , Login: db_user, Password: ***, extra: {}
[2022-05-15 19:49:53,037] {refined.py:93} INFO - Ending the data refinement process
[2022-05-15 19:49:53,039] {python.py:152} INFO - Done. Returned value was: None
[2022-05-15 19:49:53,078] {taskinstance.py:1280} INFO - Marking task as SUCCESS. dag_id=orchestrator, task_id=refined_data, execution_date=20220514T000000, start_date=20220515T194951, end_date=20220515T194953
[2022-05-15 19:49:53,186] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-05-15 19:49:53,255] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
