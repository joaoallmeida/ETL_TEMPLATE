[2022-05-15 19:27:38,935] {taskinstance.py:1035} INFO - Dependencies all met for <TaskInstance: orchestrator.extract_data manual__2022-05-15T19:22:19.061955+00:00 [queued]>
[2022-05-15 19:27:38,954] {taskinstance.py:1035} INFO - Dependencies all met for <TaskInstance: orchestrator.extract_data manual__2022-05-15T19:22:19.061955+00:00 [queued]>
[2022-05-15 19:27:38,955] {taskinstance.py:1241} INFO - 
--------------------------------------------------------------------------------
[2022-05-15 19:27:38,955] {taskinstance.py:1242} INFO - Starting attempt 2 of 2
[2022-05-15 19:27:38,955] {taskinstance.py:1243} INFO - 
--------------------------------------------------------------------------------
[2022-05-15 19:27:38,999] {taskinstance.py:1262} INFO - Executing <Task(PythonOperator): extract_data> on 2022-05-15 19:22:19.061955+00:00
[2022-05-15 19:27:39,004] {standard_task_runner.py:52} INFO - Started process 553 to run task
[2022-05-15 19:27:39,007] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'orchestrator', 'extract_data', 'manual__2022-05-15T19:22:19.061955+00:00', '--job-id', '44', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmpykrquo4a', '--error-file', '/tmp/tmpzpycrddg']
[2022-05-15 19:27:39,008] {standard_task_runner.py:77} INFO - Job 44: Subtask extract_data
[2022-05-15 19:27:39,074] {logging_mixin.py:109} INFO - Running <TaskInstance: orchestrator.extract_data manual__2022-05-15T19:22:19.061955+00:00 [running]> on host 87efc59194bd
[2022-05-15 19:27:39,205] {taskinstance.py:1414} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=***@example.com
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=orchestrator
AIRFLOW_CTX_TASK_ID=extract_data
AIRFLOW_CTX_EXECUTION_DATE=2022-05-15T19:22:19.061955+00:00
AIRFLOW_CTX_DAG_RUN_ID=manual__2022-05-15T19:22:19.061955+00:00
[2022-05-15 19:27:39,206] {extract.py:20} INFO - Extracting data from API
[2022-05-15 19:27:39,224] {base.py:79} INFO - Using connection to: id: MySql Localhost. Host: 192.168.15.14, Port: 3306, Schema: , Login: db_user, Password: ***, extra: {}
[2022-05-15 19:27:39,351] {taskinstance.py:1686} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
  File "/usr/local/lib/python3.6/site-packages/pymysql/cursors.py", line 148, in execute
    result = self._query(query)
  File "/usr/local/lib/python3.6/site-packages/pymysql/cursors.py", line 310, in _query
    conn.query(q)
  File "/usr/local/lib/python3.6/site-packages/pymysql/connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/usr/local/lib/python3.6/site-packages/pymysql/connections.py", line 775, in _read_query_result
    result.read()
  File "/usr/local/lib/python3.6/site-packages/pymysql/connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "/usr/local/lib/python3.6/site-packages/pymysql/connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "/usr/local/lib/python3.6/site-packages/pymysql/protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "/usr/local/lib/python3.6/site-packages/pymysql/err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1452, 'Cannot add or update a child row: a foreign key constraint fails (`monitoring`.`etl_logging`, CONSTRAINT `fk_process` FOREIGN KEY (`process_id`) REFERENCES `etl_process` (`process_id`))')

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1324, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1443, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1494, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 151, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 162, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/ETL/extract.py", line 21, in ExtractData
    InsertLog(1,'yts_movies','InProgress')
  File "/opt/airflow/dags/ETL/Functions/etl_monitor.py", line 60, in InsertLog
    raise e
  File "/opt/airflow/dags/ETL/Functions/etl_monitor.py", line 36, in InsertLog
    df_log_insert.to_sql(log_table,dbconn,if_exists='append',index=False)
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/core/generic.py", line 2615, in to_sql
    method=method,
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/sql.py", line 598, in to_sql
    method=method,
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/sql.py", line 1406, in to_sql
    raise err
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/sql.py", line 1398, in to_sql
    table.insert(chunksize, method=method)
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/sql.py", line 830, in insert
    exec_insert(conn, keys, chunk_iter)
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/sql.py", line 747, in _execute_insert
    conn.execute(self.table.insert(), data)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
  File "/usr/local/lib/python3.6/site-packages/pymysql/cursors.py", line 148, in execute
    result = self._query(query)
  File "/usr/local/lib/python3.6/site-packages/pymysql/cursors.py", line 310, in _query
    conn.query(q)
  File "/usr/local/lib/python3.6/site-packages/pymysql/connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/usr/local/lib/python3.6/site-packages/pymysql/connections.py", line 775, in _read_query_result
    result.read()
  File "/usr/local/lib/python3.6/site-packages/pymysql/connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "/usr/local/lib/python3.6/site-packages/pymysql/connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "/usr/local/lib/python3.6/site-packages/pymysql/protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "/usr/local/lib/python3.6/site-packages/pymysql/err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
sqlalchemy.exc.IntegrityError: (pymysql.err.IntegrityError) (1452, 'Cannot add or update a child row: a foreign key constraint fails (`monitoring`.`etl_logging`, CONSTRAINT `fk_process` FOREIGN KEY (`process_id`) REFERENCES `etl_process` (`process_id`))')
[SQL: INSERT INTO etl_logging (process_id, table_name, start_date, complete_date, row_count, `status`, error_message) VALUES (%(process_id)s, %(table_name)s, %(start_date)s, %(complete_date)s, %(row_count)s, %(status)s, %(error_message)s)]
[parameters: {'process_id': 1, 'table_name': 'yts_movies', 'start_date': datetime.datetime(2022, 5, 15, 19, 27, 39, 243804), 'complete_date': None, 'row_count': 0, 'status': 'InProgress', 'error_message': None}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2022-05-15 19:27:39,406] {taskinstance.py:1280} INFO - Marking task as FAILED. dag_id=orchestrator, task_id=extract_data, execution_date=20220515T192219, start_date=20220515T192738, end_date=20220515T192739
[2022-05-15 19:27:39,443] {standard_task_runner.py:91} ERROR - Failed to execute job 44 for task extract_data
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
  File "/usr/local/lib/python3.6/site-packages/pymysql/cursors.py", line 148, in execute
    result = self._query(query)
  File "/usr/local/lib/python3.6/site-packages/pymysql/cursors.py", line 310, in _query
    conn.query(q)
  File "/usr/local/lib/python3.6/site-packages/pymysql/connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/usr/local/lib/python3.6/site-packages/pymysql/connections.py", line 775, in _read_query_result
    result.read()
  File "/usr/local/lib/python3.6/site-packages/pymysql/connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "/usr/local/lib/python3.6/site-packages/pymysql/connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "/usr/local/lib/python3.6/site-packages/pymysql/protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "/usr/local/lib/python3.6/site-packages/pymysql/err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1452, 'Cannot add or update a child row: a foreign key constraint fails (`monitoring`.`etl_logging`, CONSTRAINT `fk_process` FOREIGN KEY (`process_id`) REFERENCES `etl_process` (`process_id`))')

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 292, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1324, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1443, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1494, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 151, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 162, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/ETL/extract.py", line 21, in ExtractData
    InsertLog(1,'yts_movies','InProgress')
  File "/opt/airflow/dags/ETL/Functions/etl_monitor.py", line 60, in InsertLog
    raise e
  File "/opt/airflow/dags/ETL/Functions/etl_monitor.py", line 36, in InsertLog
    df_log_insert.to_sql(log_table,dbconn,if_exists='append',index=False)
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/core/generic.py", line 2615, in to_sql
    method=method,
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/sql.py", line 598, in to_sql
    method=method,
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/sql.py", line 1406, in to_sql
    raise err
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/sql.py", line 1398, in to_sql
    table.insert(chunksize, method=method)
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/sql.py", line 830, in insert
    exec_insert(conn, keys, chunk_iter)
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/sql.py", line 747, in _execute_insert
    conn.execute(self.table.insert(), data)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
  File "/usr/local/lib/python3.6/site-packages/pymysql/cursors.py", line 148, in execute
    result = self._query(query)
  File "/usr/local/lib/python3.6/site-packages/pymysql/cursors.py", line 310, in _query
    conn.query(q)
  File "/usr/local/lib/python3.6/site-packages/pymysql/connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/usr/local/lib/python3.6/site-packages/pymysql/connections.py", line 775, in _read_query_result
    result.read()
  File "/usr/local/lib/python3.6/site-packages/pymysql/connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "/usr/local/lib/python3.6/site-packages/pymysql/connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "/usr/local/lib/python3.6/site-packages/pymysql/protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "/usr/local/lib/python3.6/site-packages/pymysql/err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
sqlalchemy.exc.IntegrityError: (pymysql.err.IntegrityError) (1452, 'Cannot add or update a child row: a foreign key constraint fails (`monitoring`.`etl_logging`, CONSTRAINT `fk_process` FOREIGN KEY (`process_id`) REFERENCES `etl_process` (`process_id`))')
[SQL: INSERT INTO etl_logging (process_id, table_name, start_date, complete_date, row_count, `status`, error_message) VALUES (%(process_id)s, %(table_name)s, %(start_date)s, %(complete_date)s, %(row_count)s, %(status)s, %(error_message)s)]
[parameters: {'process_id': 1, 'table_name': 'yts_movies', 'start_date': datetime.datetime(2022, 5, 15, 19, 27, 39, 243804), 'complete_date': None, 'row_count': 0, 'status': 'InProgress', 'error_message': None}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2022-05-15 19:27:39,460] {local_task_job.py:154} INFO - Task exited with return code 1
[2022-05-15 19:27:39,543] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-05-15 19:27:44,339] {taskinstance.py:1035} INFO - Dependencies all met for <TaskInstance: orchestrator.extract_data scheduled__2022-05-14T00:00:00+00:00 [queued]>
[2022-05-15 19:27:44,380] {taskinstance.py:1035} INFO - Dependencies all met for <TaskInstance: orchestrator.extract_data scheduled__2022-05-14T00:00:00+00:00 [queued]>
[2022-05-15 19:27:44,380] {taskinstance.py:1241} INFO - 
--------------------------------------------------------------------------------
[2022-05-15 19:27:44,380] {taskinstance.py:1242} INFO - Starting attempt 2 of 2
[2022-05-15 19:27:44,380] {taskinstance.py:1243} INFO - 
--------------------------------------------------------------------------------
[2022-05-15 19:27:44,413] {taskinstance.py:1262} INFO - Executing <Task(PythonOperator): extract_data> on 2022-05-14 00:00:00+00:00
[2022-05-15 19:27:44,418] {standard_task_runner.py:52} INFO - Started process 563 to run task
[2022-05-15 19:27:44,421] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'orchestrator', 'extract_data', 'scheduled__2022-05-14T00:00:00+00:00', '--job-id', '45', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmpuxxcak4g', '--error-file', '/tmp/tmpq62a8ymd']
[2022-05-15 19:27:44,422] {standard_task_runner.py:77} INFO - Job 45: Subtask extract_data
[2022-05-15 19:27:44,488] {logging_mixin.py:109} INFO - Running <TaskInstance: orchestrator.extract_data scheduled__2022-05-14T00:00:00+00:00 [running]> on host 87efc59194bd
[2022-05-15 19:27:44,620] {taskinstance.py:1414} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=***@example.com
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=orchestrator
AIRFLOW_CTX_TASK_ID=extract_data
AIRFLOW_CTX_EXECUTION_DATE=2022-05-14T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-05-14T00:00:00+00:00
[2022-05-15 19:27:44,620] {extract.py:20} INFO - Extracting data from API
[2022-05-15 19:27:44,637] {base.py:79} INFO - Using connection to: id: MySql Localhost. Host: 192.168.15.14, Port: 3306, Schema: , Login: db_user, Password: ***, extra: {}
[2022-05-15 19:27:44,736] {taskinstance.py:1686} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
  File "/usr/local/lib/python3.6/site-packages/pymysql/cursors.py", line 148, in execute
    result = self._query(query)
  File "/usr/local/lib/python3.6/site-packages/pymysql/cursors.py", line 310, in _query
    conn.query(q)
  File "/usr/local/lib/python3.6/site-packages/pymysql/connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/usr/local/lib/python3.6/site-packages/pymysql/connections.py", line 775, in _read_query_result
    result.read()
  File "/usr/local/lib/python3.6/site-packages/pymysql/connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "/usr/local/lib/python3.6/site-packages/pymysql/connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "/usr/local/lib/python3.6/site-packages/pymysql/protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "/usr/local/lib/python3.6/site-packages/pymysql/err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1452, 'Cannot add or update a child row: a foreign key constraint fails (`monitoring`.`etl_logging`, CONSTRAINT `fk_process` FOREIGN KEY (`process_id`) REFERENCES `etl_process` (`process_id`))')

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1324, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1443, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1494, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 151, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 162, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/ETL/extract.py", line 21, in ExtractData
    InsertLog(1,'yts_movies','InProgress')
  File "/opt/airflow/dags/ETL/Functions/etl_monitor.py", line 60, in InsertLog
    raise e
  File "/opt/airflow/dags/ETL/Functions/etl_monitor.py", line 36, in InsertLog
    df_log_insert.to_sql(log_table,dbconn,if_exists='append',index=False)
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/core/generic.py", line 2615, in to_sql
    method=method,
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/sql.py", line 598, in to_sql
    method=method,
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/sql.py", line 1406, in to_sql
    raise err
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/sql.py", line 1398, in to_sql
    table.insert(chunksize, method=method)
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/sql.py", line 830, in insert
    exec_insert(conn, keys, chunk_iter)
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/sql.py", line 747, in _execute_insert
    conn.execute(self.table.insert(), data)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
  File "/usr/local/lib/python3.6/site-packages/pymysql/cursors.py", line 148, in execute
    result = self._query(query)
  File "/usr/local/lib/python3.6/site-packages/pymysql/cursors.py", line 310, in _query
    conn.query(q)
  File "/usr/local/lib/python3.6/site-packages/pymysql/connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/usr/local/lib/python3.6/site-packages/pymysql/connections.py", line 775, in _read_query_result
    result.read()
  File "/usr/local/lib/python3.6/site-packages/pymysql/connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "/usr/local/lib/python3.6/site-packages/pymysql/connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "/usr/local/lib/python3.6/site-packages/pymysql/protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "/usr/local/lib/python3.6/site-packages/pymysql/err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
sqlalchemy.exc.IntegrityError: (pymysql.err.IntegrityError) (1452, 'Cannot add or update a child row: a foreign key constraint fails (`monitoring`.`etl_logging`, CONSTRAINT `fk_process` FOREIGN KEY (`process_id`) REFERENCES `etl_process` (`process_id`))')
[SQL: INSERT INTO etl_logging (process_id, table_name, start_date, complete_date, row_count, `status`, error_message) VALUES (%(process_id)s, %(table_name)s, %(start_date)s, %(complete_date)s, %(row_count)s, %(status)s, %(error_message)s)]
[parameters: {'process_id': 1, 'table_name': 'yts_movies', 'start_date': datetime.datetime(2022, 5, 15, 19, 27, 44, 656397), 'complete_date': None, 'row_count': 0, 'status': 'InProgress', 'error_message': None}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2022-05-15 19:27:44,798] {taskinstance.py:1280} INFO - Marking task as FAILED. dag_id=orchestrator, task_id=extract_data, execution_date=20220514T000000, start_date=20220515T192744, end_date=20220515T192744
[2022-05-15 19:27:44,836] {standard_task_runner.py:91} ERROR - Failed to execute job 45 for task extract_data
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
  File "/usr/local/lib/python3.6/site-packages/pymysql/cursors.py", line 148, in execute
    result = self._query(query)
  File "/usr/local/lib/python3.6/site-packages/pymysql/cursors.py", line 310, in _query
    conn.query(q)
  File "/usr/local/lib/python3.6/site-packages/pymysql/connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/usr/local/lib/python3.6/site-packages/pymysql/connections.py", line 775, in _read_query_result
    result.read()
  File "/usr/local/lib/python3.6/site-packages/pymysql/connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "/usr/local/lib/python3.6/site-packages/pymysql/connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "/usr/local/lib/python3.6/site-packages/pymysql/protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "/usr/local/lib/python3.6/site-packages/pymysql/err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1452, 'Cannot add or update a child row: a foreign key constraint fails (`monitoring`.`etl_logging`, CONSTRAINT `fk_process` FOREIGN KEY (`process_id`) REFERENCES `etl_process` (`process_id`))')

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 292, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1324, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1443, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1494, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 151, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 162, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/ETL/extract.py", line 21, in ExtractData
    InsertLog(1,'yts_movies','InProgress')
  File "/opt/airflow/dags/ETL/Functions/etl_monitor.py", line 60, in InsertLog
    raise e
  File "/opt/airflow/dags/ETL/Functions/etl_monitor.py", line 36, in InsertLog
    df_log_insert.to_sql(log_table,dbconn,if_exists='append',index=False)
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/core/generic.py", line 2615, in to_sql
    method=method,
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/sql.py", line 598, in to_sql
    method=method,
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/sql.py", line 1406, in to_sql
    raise err
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/sql.py", line 1398, in to_sql
    table.insert(chunksize, method=method)
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/sql.py", line 830, in insert
    exec_insert(conn, keys, chunk_iter)
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/sql.py", line 747, in _execute_insert
    conn.execute(self.table.insert(), data)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
  File "/usr/local/lib/python3.6/site-packages/pymysql/cursors.py", line 148, in execute
    result = self._query(query)
  File "/usr/local/lib/python3.6/site-packages/pymysql/cursors.py", line 310, in _query
    conn.query(q)
  File "/usr/local/lib/python3.6/site-packages/pymysql/connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/usr/local/lib/python3.6/site-packages/pymysql/connections.py", line 775, in _read_query_result
    result.read()
  File "/usr/local/lib/python3.6/site-packages/pymysql/connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "/usr/local/lib/python3.6/site-packages/pymysql/connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "/usr/local/lib/python3.6/site-packages/pymysql/protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "/usr/local/lib/python3.6/site-packages/pymysql/err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
sqlalchemy.exc.IntegrityError: (pymysql.err.IntegrityError) (1452, 'Cannot add or update a child row: a foreign key constraint fails (`monitoring`.`etl_logging`, CONSTRAINT `fk_process` FOREIGN KEY (`process_id`) REFERENCES `etl_process` (`process_id`))')
[SQL: INSERT INTO etl_logging (process_id, table_name, start_date, complete_date, row_count, `status`, error_message) VALUES (%(process_id)s, %(table_name)s, %(start_date)s, %(complete_date)s, %(row_count)s, %(status)s, %(error_message)s)]
[parameters: {'process_id': 1, 'table_name': 'yts_movies', 'start_date': datetime.datetime(2022, 5, 15, 19, 27, 44, 656397), 'complete_date': None, 'row_count': 0, 'status': 'InProgress', 'error_message': None}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2022-05-15 19:27:44,874] {local_task_job.py:154} INFO - Task exited with return code 1
[2022-05-15 19:27:45,001] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-05-15 19:40:14,504] {taskinstance.py:1035} INFO - Dependencies all met for <TaskInstance: orchestrator.extract_data scheduled__2022-05-14T00:00:00+00:00 [queued]>
[2022-05-15 19:40:14,569] {taskinstance.py:1035} INFO - Dependencies all met for <TaskInstance: orchestrator.extract_data scheduled__2022-05-14T00:00:00+00:00 [queued]>
[2022-05-15 19:40:14,570] {taskinstance.py:1241} INFO - 
--------------------------------------------------------------------------------
[2022-05-15 19:40:14,570] {taskinstance.py:1242} INFO - Starting attempt 2 of 2
[2022-05-15 19:40:14,570] {taskinstance.py:1243} INFO - 
--------------------------------------------------------------------------------
[2022-05-15 19:40:14,614] {taskinstance.py:1262} INFO - Executing <Task(PythonOperator): extract_data> on 2022-05-14 00:00:00+00:00
[2022-05-15 19:40:14,618] {standard_task_runner.py:52} INFO - Started process 1084 to run task
[2022-05-15 19:40:14,622] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'orchestrator', 'extract_data', 'scheduled__2022-05-14T00:00:00+00:00', '--job-id', '48', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmph13jz0p0', '--error-file', '/tmp/tmpetlpjlsn']
[2022-05-15 19:40:14,623] {standard_task_runner.py:77} INFO - Job 48: Subtask extract_data
[2022-05-15 19:40:14,692] {logging_mixin.py:109} INFO - Running <TaskInstance: orchestrator.extract_data scheduled__2022-05-14T00:00:00+00:00 [running]> on host 87efc59194bd
[2022-05-15 19:40:14,806] {taskinstance.py:1414} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=***@example.com
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=orchestrator
AIRFLOW_CTX_TASK_ID=extract_data
AIRFLOW_CTX_EXECUTION_DATE=2022-05-14T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-05-14T00:00:00+00:00
[2022-05-15 19:40:14,807] {extract.py:20} INFO - Extracting data from API
[2022-05-15 19:40:14,825] {base.py:79} INFO - Using connection to: id: MySql Localhost. Host: 192.168.15.14, Port: 3306, Schema: , Login: db_user, Password: ***, extra: {}
[2022-05-15 19:40:14,978] {base.py:79} INFO - Using connection to: id: MySql Localhost. Host: 192.168.15.14, Port: 3306, Schema: , Login: db_user, Password: ***, extra: {}
[2022-05-15 19:40:27,105] {extract.py:45} INFO - Get load data
[2022-05-15 19:40:27,123] {utils_functions.py:98} ERROR - Table TableName not found
[2022-05-15 19:40:27,123] {extract.py:58} ERROR - Error in extract process: Table TableName not found
[2022-05-15 19:40:27,139] {base.py:79} INFO - Using connection to: id: MySql Localhost. Host: 192.168.15.14, Port: 3306, Schema: , Login: db_user, Password: ***, extra: {}
[2022-05-15 19:40:27,326] {extract.py:63} INFO - Completing extract from api
[2022-05-15 19:40:27,327] {taskinstance.py:1686} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/sql.py", line 269, in read_sql_table
    meta.reflect(only=[table_name], views=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/schema.py", line 4612, in reflect
    "in %r%s: (%s)" % (bind.engine, s, ", ".join(missing))
sqlalchemy.exc.InvalidRequestError: Could not reflect: requested table(s) not available in Engine(mysql+pymysql://db_user:***@192.168.15.14:3306/bronze): (TableName)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/airflow/dags/ETL/Functions/utils_functions.py", line 92, in getChanges
    df_target = pd.read_sql_table(table, dbconn)
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/sql.py", line 271, in read_sql_table
    raise ValueError(f"Table {table_name} not found") from err
ValueError: Table TableName not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/airflow/dags/ETL/extract.py", line 46, in ExtractData
    df = getChanges(df,TableName,dbconn)
  File "/opt/airflow/dags/ETL/Functions/utils_functions.py", line 99, in getChanges
    raise TypeError(e)
TypeError: Table TableName not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1324, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1443, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1494, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 151, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 162, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/ETL/extract.py", line 60, in ExtractData
    raise TypeError(e)
TypeError: Table TableName not found
[2022-05-15 19:40:27,371] {taskinstance.py:1280} INFO - Marking task as FAILED. dag_id=orchestrator, task_id=extract_data, execution_date=20220514T000000, start_date=20220515T194014, end_date=20220515T194027
[2022-05-15 19:40:27,418] {standard_task_runner.py:91} ERROR - Failed to execute job 48 for task extract_data
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/sql.py", line 269, in read_sql_table
    meta.reflect(only=[table_name], views=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/schema.py", line 4612, in reflect
    "in %r%s: (%s)" % (bind.engine, s, ", ".join(missing))
sqlalchemy.exc.InvalidRequestError: Could not reflect: requested table(s) not available in Engine(mysql+pymysql://db_user:***@192.168.15.14:3306/bronze): (TableName)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/airflow/dags/ETL/Functions/utils_functions.py", line 92, in getChanges
    df_target = pd.read_sql_table(table, dbconn)
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/sql.py", line 271, in read_sql_table
    raise ValueError(f"Table {table_name} not found") from err
ValueError: Table TableName not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/airflow/dags/ETL/extract.py", line 46, in ExtractData
    df = getChanges(df,TableName,dbconn)
  File "/opt/airflow/dags/ETL/Functions/utils_functions.py", line 99, in getChanges
    raise TypeError(e)
TypeError: Table TableName not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 292, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1324, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1443, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1494, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 151, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 162, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/ETL/extract.py", line 60, in ExtractData
    raise TypeError(e)
TypeError: Table TableName not found
[2022-05-15 19:40:27,438] {local_task_job.py:154} INFO - Task exited with return code 1
[2022-05-15 19:40:27,528] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
